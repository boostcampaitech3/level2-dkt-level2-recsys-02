{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from trueskill import Rating, quality_1vs1, rate_1vs1\n",
    "import math\n",
    "import trueskill\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_probability(team1, team2):\n",
    "    delta_mu = team1.mu - team2.mu\n",
    "    sum_sigma = sum([team1.sigma ** 2, team2.sigma ** 2])\n",
    "    size = 2\n",
    "    denom = math.sqrt(size * (0.05 * 0.05) + sum_sigma)\n",
    "    ts = trueskill.global_env()\n",
    "    return ts.cdf(delta_mu / denom)\n",
    "\n",
    "\n",
    "def add_trueskill(df, user_trueskill_dict, question_trueskill_dict, cv_num):\n",
    "    wp = np.zeros(len(df), dtype=np.float32)\n",
    "    umu = np.zeros(len(df), dtype=np.float32)\n",
    "    usigma = np.zeros(len(df), dtype=np.float32)\n",
    "    qmu = np.zeros(len(df), dtype=np.float32)\n",
    "    qsigma = np.zeros(len(df), dtype=np.float32)\n",
    "    for cnt,row in enumerate(tqdm(df[['userID','assessmentItemID','answerCode']].values)):\n",
    "        user_id=int(row[0])\n",
    "        content_id=row[1]\n",
    "        answered_correctly=int(row[2])\n",
    "        old_user_rating = user_trueskill_dict[user_id]\n",
    "        old_question_rating = question_trueskill_dict[content_id]\n",
    "        wp[cnt] = win_probability(old_user_rating,old_question_rating)\n",
    "        umu[cnt] = old_user_rating.mu\n",
    "        usigma[cnt] = old_user_rating.sigma\n",
    "        qmu[cnt] = old_question_rating.mu\n",
    "        qsigma[cnt] = old_question_rating.sigma\n",
    "        if answered_correctly == 1:\n",
    "            new_user_rating,new_question_rating = rate_1vs1(old_user_rating,old_question_rating)\n",
    "        else:\n",
    "            new_question_rating,new_user_rating = rate_1vs1(old_question_rating,old_user_rating)\n",
    "        user_trueskill_dict[user_id] = new_user_rating\n",
    "        question_trueskill_dict[content_id] = new_question_rating\n",
    "        \n",
    "    df[f'trueSkill_win_probability_cv{cv_num}']=wp\n",
    "    df[f'trueSkill_user_mu_cv{cv_num}']=umu\n",
    "    df[f'trueSkill_user_sigma_cv{cv_num}']=usigma\n",
    "    df[f'trueSkill_question_mu_cv{cv_num}']=qmu\n",
    "    df[f'trueSkill_question_sigma_cv{cv_num}']=qsigma\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_trueskill_without_update(df, user_trueskill_dict, question_trueskill_dict,cv_num):\n",
    "    wp = np.zeros(len(df), dtype=np.float32)\n",
    "    umu = np.zeros(len(df), dtype=np.float32)\n",
    "    usigma = np.zeros(len(df), dtype=np.float32)\n",
    "    qmu = np.zeros(len(df), dtype=np.float32)\n",
    "    qsigma = np.zeros(len(df), dtype=np.float32)\n",
    "    for cnt,row in (enumerate(tqdm(df[['userID','assessmentItemID']].values))):\n",
    "        user_id=int(row[0])\n",
    "        content_id=row[1]\n",
    "        old_user_rating = user_trueskill_dict[user_id]\n",
    "        old_question_rating = question_trueskill_dict[content_id]\n",
    "        wp[cnt] = win_probability(old_user_rating,old_question_rating)\n",
    "        umu[cnt] = old_user_rating.mu\n",
    "        usigma[cnt] = old_user_rating.sigma\n",
    "        qmu[cnt] = old_question_rating.mu\n",
    "        qsigma[cnt] = old_question_rating.sigma\n",
    "        \n",
    "    df[f'trueSkill_win_probability_cv{cv_num}']=wp\n",
    "    df[f'trueSkill_user_mu_cv{cv_num}']=umu\n",
    "    df[f'trueSkill_user_sigma_cv{cv_num}']=usigma\n",
    "    df[f'trueSkill_question_mu_cv{cv_num}']=qmu\n",
    "    df[f'trueSkill_question_sigma_cv{cv_num}']=qsigma\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/project/data/'\n",
    "csv_file_path = os.path.join(data_dir, 'total_data.csv')\n",
    "df = pd.read_csv(csv_file_path, parse_dates=['Timestamp']) \n",
    "df = df.sort_values(by=['userID', 'Timestamp']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_update(df, cv_num):\n",
    "    users_file_path = os.path.join(data_dir, f'cv1_users.pickle')\n",
    "    with open(users_file_path,'rb') as f:\n",
    "        users = pickle.load(f)\n",
    "    train_users = users['train_users']\n",
    "    test_users = users['test_users']\n",
    "\n",
    "    valid_cond1 = df['userID'].isin(train_users) == False\n",
    "    valid_cond2 = df['userID'].isin(test_users) == False\n",
    "    cv_idx = df[valid_cond1&valid_cond2].groupby('userID', as_index=False).nth(-cv_num).index\n",
    "    valid_idx = df[valid_cond1&valid_cond2].groupby('userID').tail(cv_num).index\n",
    "    \n",
    "    df['cv_idx'] = False\n",
    "    df['is_valid'] = False\n",
    "    \n",
    "    df.loc[cv_idx, 'cv_idx'] = True\n",
    "    df.loc[valid_idx, 'is_valid'] = True\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2523949 2751 2526700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2523949/2523949 [11:28<00:00, 3666.77it/s]\n",
      "100%|██████████| 2751/2751 [00:00<00:00, 127954.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2521942 4758 2526700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2521942/2521942 [10:59<00:00, 3823.96it/s]\n",
      "100%|██████████| 4758/4758 [00:00<00:00, 122337.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2519935 6765 2526700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2519935/2519935 [11:00<00:00, 3815.07it/s]\n",
      "100%|██████████| 6765/6765 [00:00<00:00, 142414.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2517928 8772 2526700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2517928/2517928 [11:06<00:00, 3780.27it/s]\n",
      "100%|██████████| 8772/8772 [00:00<00:00, 140395.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2515921 10779 2526700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2515921/2515921 [11:16<00:00, 3718.02it/s]\n",
      "100%|██████████| 10779/10779 [00:00<00:00, 143479.54it/s]\n"
     ]
    }
   ],
   "source": [
    "cv_len = 5\n",
    "\n",
    "for cv_num in range(1, 1+cv_len):\n",
    "    df = valid_update(df, cv_num)\n",
    "    \n",
    "    cond1 = df['is_valid'] == True\n",
    "    cond2 = df['answerCode'] == -1\n",
    "    test_df = df[cond1|cond2].copy()\n",
    "    train_df = df[~(cond1|cond2)].copy()\n",
    "\n",
    "    print(len(train_df),len(test_df), len(train_df) + len(test_df))\n",
    "    \n",
    "    user_trueskill_dict = defaultdict(lambda:Rating())\n",
    "    question_trueskill_dict = defaultdict(lambda:Rating())\n",
    "    train_df = add_trueskill(train_df, user_trueskill_dict, question_trueskill_dict, cv_num)\n",
    "    test_df = add_trueskill_without_update(test_df, user_trueskill_dict, question_trueskill_dict, cv_num)\n",
    "    \n",
    "    df = pd.concat([train_df, test_df])\n",
    "    df = df.sort_values(by=['userID', 'Timestamp']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([train_df, test_df])\n",
    "csv_save_path = os.path.join(data_dir, 'total_data_v2.csv')\n",
    "df.to_csv(csv_save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb38b1d5dc17143af8c4be1110e85aba63a39da7f5e57e9420b18116c934763b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
